# -*- coding: utf-8 -*-
"""
scripts/04_analysis_01_jac.py

[Task 1: Jacobian Spectral Norm Analysis]

This script performs the empirical verification of the Lipschitz continuity for the 
trained Dynamics Models (T_theta), a critical requirement for the Lyapunov stability 
proofs in Chapter 4.

It operates by:
1. Scanning the directory structure for specified experiment runs.
2. Locating the 'summary.json' files generated by the S8 validation suite (specifically 
   the robust spectral norm estimation task).
3. Extracting key statistics (Mean, Std, Max, P99) of the Jacobian spectral norm.
4. Aggregating these metrics into a Pandas DataFrame for comparison and reporting.

The resulting 'Mean' value is used to support the claim that the trained models are 
effectively non-expansive (Lipschitz constant approx. 1.0).
"""

import json, sys, traceback
import pandas as pd
from pathlib import Path

try:
    # Add the project root to sys.path to allow importing from 'src'.
    sys.path.append(str(Path(__file__).parent.parent.resolve()))
    from src.config import *
except ImportError:
    print("❌ Error: Could not import DATA_LOADER_PARAMS from src.config.")
    print("  Ensure 'src/config.py' exists and defines DATA_LOADER_PARAMS.")
    traceback.print_exc()
    sys.exit(1)
except Exception as e:
    print(f"❌ An unexpected error occurred during config import: {e}")
    traceback.print_exc()
    sys.exit(1)

# Define the root directory containing all trained model artifacts.
BASE_DIR = PATHS["dynamics_model_dir"]

# List of experiments to analyze.
# Format: ("Display Name", "Relative/Path/To/Experiment/Directory")
# These paths correspond to the structure defined in the project hierarchy.
EXPERIMENTS = [
    # Milestone 0: Baseline unconstrained model
    ("00_Base", "00_Base"),
    # Milestone 1: Lipschitz Continuity via Spectral Normalization
    ("01_OnlySN", "01_Continuity/01_OnlySN"),
    ("01_SN_jac_1e-3", "01_Continuity/02_SN_1e-3"),
    # Milestone 2: Prediction Accuracy Enhancements
    ("02_LearnP_Scheduler", "02_Accuracy/01_Learn_P_lr_Scheduler"),
    ("02_Text_Decoder", "02_Accuracy/02_TextEmb_DecoderState"),
    ("02_Uncertainty", "02_Accuracy/03_UncertaintyWeights"),
    ("02_SeparateHeadEH", "02_Accuracy/04_SeparateHeadEH"),
    ("02_Predict_Delta", "02_Accuracy/05_Predict_Delta"),
    ("02_MultiHead", "02_Accuracy/06_MultiHead"),
    # Milestone 3: Stability Constraints
    ("03_Single_CLF_0.4", "03_Stability/01_Single_CLF/01_CLF_0.4"),
    ("03_NCLF_1.0", "03_Stability/02_NCLF/02_NCLF_1.0"),
    ("03_Gumbel", "03_Stability/02_NCLF/04_Gumble_Softmax"),
    ("03_Epsilon_Greedy", "03_Stability/03_epsilon_Greedy/01_default"),
    ("03_BPTT", "03_Stability/04_bptt/03_H_8_bptt_4"),
    ("03_CVaR", "03_Stability/05_CVaR/01_alpha_0.7"),
    ("03_CBF", "03_Stability/061_CBF/02_λ_0.5_crit_0.7_alpha_0.5"),
    ("03_Cox", "03_Stability/062_Cox/02_λ_0.5_event_thr_0.8"),
    ("03_ADT", "03_Stability/063_ADT/01_λ_0.7"),
    # Milestone 4: Curriculum Learning
    ("04_Curriculum_5", "04_Curriculum/01_phase1_epochs_5"),
    ("04_Curriculum_10", "04_Curriculum/02_phase1_epochs_10"),
    # Final Champion Model
    ("Champion", "Champion")
]

def analyze_jacobian_results():
    """
    Main execution function. Iterates through the experiment list, loads the 
    S8 validation summary, and prints a comparative table of Jacobian statistics.
    """
    results_data = []

    print("--- Starting Jacobian Spectral Norm Analysis ---")

    for name, rel_path in EXPERIMENTS:
        # Construct path to the S8 validation summary for the best epoch.
        # This JSON file contains the aggregated results of the robustness tests.
        summary_path = BASE_DIR / rel_path / "s8_validation_epoch_best" / "summary.json"

        # Skip if the experiment hasn't completed or S8 validation wasn't run.
        if not summary_path.exists(): continue

        try:
            with open(summary_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # Retrieve the Jacobian statistics dictionary.
            jacobian_stats = data.get("results", {}).get("jacobian")

            if not jacobian_stats: continue
            
            # Extract key metrics: Mean norm, Standard Deviation, Max norm, 99th Percentile.
            results_data.append({
                "Experiment": name,
                "Mean": jacobian_stats.get("mean"),
                "Std": jacobian_stats.get("std"),
                "Max": jacobian_stats.get("max"),
                "P99": jacobian_stats.get("percentile_99")
            })

        except (json.JSONDecodeError, KeyError): continue

    if not results_data:
        print("\nNo valid Jacobian results found in any experiment.")
        return

    # Convert to DataFrame for clean tabular display.
    df = pd.DataFrame(results_data)
    df = df.set_index("Experiment")

    # Configure Pandas display options for readability.
    pd.set_option('display.precision', 4)
    pd.set_option('display.width', 120)

    print("\n--- Jacobian Spectral Norm Summary ---")
    print(df)

if __name__ == "__main__":
    analyze_jacobian_results()
